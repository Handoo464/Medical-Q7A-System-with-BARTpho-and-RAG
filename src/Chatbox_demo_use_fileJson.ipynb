{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2720,"status":"ok","timestamp":1722664906972,"user":{"displayName":"Trần văn Luân","userId":"01151775694925135648"},"user_tz":-420},"id":"qt9ay2nme5OQ","outputId":"b2c8eeca-c600-4797-b7de-c0198881d3db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#/content/drive/MyDrive/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10070,"status":"ok","timestamp":1722664917039,"user":{"displayName":"Trần văn Luân","userId":"01151775694925135648"},"user_tz":-420},"id":"oRfJMFLXiCbV","outputId":"a121235e-3cc0-49ec-ec7e-49bf70ef223b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow\u003e=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill\u003c0.3.9,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests\u003e=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm\u003e=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec\u003c=2024.5.0,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]\u003c=2024.5.0,\u003e=2023.1.0-\u003edatasets) (2024.5.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub\u003e=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (23.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (6.0.5)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (1.9.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets) (4.0.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.21.2-\u003edatasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.32.2-\u003edatasets) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.32.2-\u003edatasets) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.32.2-\u003edatasets) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.32.2-\u003edatasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2024.1)\n","Requirement already satisfied: tzdata\u003e=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets) (2024.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas-\u003edatasets) (1.16.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"markdown","metadata":{"id":"KlOZmRMNb7RG"},"source":["**1. Import Necessaries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJwaDofzZGp_"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BartTokenizer, BartForConditionalGeneration\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","from torch.cuda.amp import GradScaler, autocast\n","import os\n","import logging"]},{"cell_type":"markdown","metadata":{"id":"pGtX4PAqwrew"},"source":["#Data Loading and Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSGJanEocLQW"},"outputs":[],"source":["data_path = '/content/drive/MyDrive/ChatBox/data/processed_output.csv'  # Update with your data path\n","df  = pd.read_csv(data_path)\n","\n","df .head()\n","\n","# Prepare data: Assume df['Content'] is the column containing conversation data\n","train_texts = df['Content'].tolist()\n","\n","# Split data into train and validation sets\n","from sklearn.model_selection import train_test_split\n","train_texts, val_texts = train_test_split(train_texts, test_size=0.1, random_state=42)\n"]},{"cell_type":"markdown","metadata":{"id":"U7Zn3dRPw6IR"},"source":["#Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16331,"status":"ok","timestamp":1722664948799,"user":{"displayName":"Trần văn Luân","userId":"01151775694925135648"},"user_tz":-420},"id":"cvOAYdpQw7Z8","outputId":"08518bba-b917-4bd7-a821-415aa4df52df"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["# Initialize BART tokenizer\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n","\n","# Tokenize data\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)"]},{"cell_type":"markdown","metadata":{"id":"nXT7GdCbyn3j"},"source":["#Prepare Data Loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-w2NLir3yom8"},"outputs":[],"source":["class ConversationDataset(Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","# Create dataset instances\n","train_dataset = ConversationDataset(train_encodings)\n","val_dataset = ConversationDataset(val_encodings)\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # Thay đổi batch_size tùy thuộc vào bộ nhớ GPU\n","val_loader = DataLoader(val_dataset, batch_size=4)"]},{"cell_type":"markdown","metadata":{"id":"7wCsAcpjxgZQ"},"source":["#Initialize the BART Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3218,"status":"ok","timestamp":1722665063385,"user":{"displayName":"Trần văn Luân","userId":"01151775694925135648"},"user_tz":-420},"id":"2E_iJLa7xhhY","outputId":"d3591958-e22c-4bb2-f553-bcd42b4ba722"},"outputs":[{"data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartDecoderLayer(\n","          (self_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartSdpaAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Chọn thiết bị (GPU nếu có, nếu không thì sử dụng CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Load pre-trained BART model\n","model = BartForConditionalGeneration.from_pretrained('facebook/bart-base', use_cache=False).to(device)\n","\n","# Set model to training mode\n","model.train()\n","\n","# Move model to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"N54HRVhwxkqO"},"source":["#Define Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1722665067083,"user":{"displayName":"Trần văn Luân","userId":"01151775694925135648"},"user_tz":-420},"id":"gvhCgtO10Oac","outputId":"1d2f5130-3bc7-431e-b6ec-8fbc129d8b42"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\n"]}],"source":["# Tham số huấn luyện\n","epochs = 3\n","logging_steps = 50\n","accumulation_steps = 1\n","scaler = GradScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":867,"status":"ok","timestamp":1722665070692,"user":{"displayName":"Trần văn Luân","userId":"01151775694925135648"},"user_tz":-420},"id":"nd3FPHExx5tV","outputId":"7ea5d7fb-b367-4a01-c364-4e6f6cdeb134"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# Step 6: Define Training Loop\n","\n","# Cài đặt optimizer và scheduler\n","optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n","total_steps = len(train_loader) * epochs  # Tổng số bước huấn luyện\n","\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=total_steps\n",")\n","\n","def compute_loss(logits, labels):\n","    loss_fct = CrossEntropyLoss()\n","    return loss_fct(logits.view(-1, model.config.vocab_size), labels.view(-1))"]},{"cell_type":"markdown","metadata":{"id":"wYK2EqcZx_fl"},"source":["#Train the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"zbF3LBNayCVC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"name":"stderr","output_type":"stream","text":["Iteration:   1%|▏         | 1/67 [00:59\u003c1:05:57, 59.96s/it]"]},{"name":"stdout","output_type":"stream","text":["Step 0: Loss 0.34540289640426636\n"]},{"name":"stderr","output_type":"stream","text":["Iteration:  76%|███████▌  | 51/67 [37:32\u003c11:48, 44.27s/it]"]},{"name":"stdout","output_type":"stream","text":["Step 50: Loss 0.0022737684193998575\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 67/67 [49:18\u003c00:00, 44.16s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.06065468109829908\n","Epoch 2/3\n"]},{"name":"stderr","output_type":"stream","text":["Iteration:   1%|▏         | 1/67 [00:45\u003c49:54, 45.37s/it]"]},{"name":"stdout","output_type":"stream","text":["Step 0: Loss 0.07900087535381317\n"]},{"name":"stderr","output_type":"stream","text":["Iteration:  76%|███████▌  | 51/67 [37:08\u003c11:36, 43.53s/it]"]},{"name":"stdout","output_type":"stream","text":["Step 50: Loss 0.002710364991798997\n"]},{"name":"stderr","output_type":"stream","text":["Iteration:  79%|███████▉  | 53/67 [38:33\u003c10:02, 43.01s/it]"]}],"source":["# Vòng lặp huấn luyện\n","for epoch in range(epochs):\n","    print(f'Epoch {epoch+1}/{epochs}')\n","    model.train()\n","    epoch_iterator = tqdm(train_loader, desc=\"Iteration\")\n","\n","    for step, batch in enumerate(epoch_iterator):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","\n","        with autocast():\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n","            loss = outputs.loss / accumulation_steps\n","\n","        scaler.scale(loss).backward()\n","\n","        if (step + 1) % accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            scheduler.step()\n","            model.zero_grad()\n","\n","        if step % logging_steps == 0:\n","            print(f'Step {step}: Loss {loss.item()}')\n","\n","    # Đánh giá trên tập validation\n","    model.eval()\n","    eval_loss = 0\n","    for batch in val_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n","            eval_loss += outputs.loss.item()\n","\n","    eval_loss /= len(val_loader)\n","    print(f'Validation Loss: {eval_loss}')\n","\n","    # # Dọn dẹp bộ nhớ\n","    # gc.collect()\n","    # torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"N8dflfyFyM2k"},"source":["#Save Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IKDX7uVPyS5c"},"outputs":[],"source":["# Save the fine-tuned model\n","model.save_pretrained('/content/drive/MyDrive/ChatBox/model/fine_tuned_bart')\n","tokenizer.save_pretrained('/content/drive/MyDrive/ChatBox/model/fine_tuned_bart')"]},{"cell_type":"markdown","metadata":{"id":"1698euVdz-k1"},"source":["#Generate Response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26pTbGsVz_0b"},"outputs":[],"source":["# Set the maximum length for input sequences\n","max_length = 512\n","\n","def generate_response(input_text: str) -\u003e str:\n","    \"\"\"\n","    Generate a response for the input text.\n","\n","    Args:\n","        input_text (str): Input text for generating the response.\n","\n","    Returns:\n","        str: The generated response by the Chatbot.\n","    \"\"\"\n","    # Encode the input text\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt',\n","                                 truncation=True, padding='longest',\n","                                 max_length=max_length)\n","    input_ids = input_ids.to(device)\n","\n","    with torch.no_grad():\n","        # Generate output using top-k and top-p sampling\n","        output = model.generate(\n","            input_ids,\n","            max_length=max_length,\n","            num_beams=5,           # Increase number of beams for more diverse results\n","            no_repeat_ngram_size=2, # Avoid repeating n-grams\n","            num_return_sequences=1, # Number of sequences to return\n","            early_stopping=True,\n","            temperature=0.7,       # Control randomness\n","            top_k=50,              # Limit sampling pool\n","            top_p=0.95             # Nucleus sampling\n","        )\n","\n","    # Decode the generated output\n","    response = tokenizer.decode(output[0], skip_special_tokens=True)\n","    return response\n","\n","# Test the generate_response function\n","input_text = \"dấu hiệu bệnh nhiễm trùng\"\n","response = generate_response(input_text)\n","print(\"Input:\", input_text)\n","print(\"Response:\", response)"]},{"cell_type":"markdown","metadata":{"id":"Sue4KT830IXb"},"source":["#Plot Training Performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3oIYcqf0Ezl"},"outputs":[],"source":["\"\"\"\n","## Plot Training Performance\n","\n","Visualize the loss evolution over epochs and batches.\n","\"\"\"\n","\n","# Dummy data for epoch and batch losses (replace with actual training data)\n","epoch_losses = [0.9, 0.7, 0.5, 0.3]\n","batch_losses = [0.95, 0.85, 0.75, 0.65, 0.6, 0.55, 0.5, 0.45]\n","\n","def plot_performance(show_epoch_loss: bool = True, show_batch_loss: bool = True):\n","    \"\"\"\n","    Plot the training performance.\n","\n","    Args:\n","        show_epoch_loss (bool, optional): Whether to plot the epoch-wise average loss. Defaults to True.\n","        show_batch_loss (bool, optional): Whether to plot the batch-wise loss. Defaults to True.\n","    \"\"\"\n","    if show_epoch_loss:\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(range(1, len(epoch_losses) + 1), epoch_losses, marker='o', label='Epoch Loss')\n","        plt.xlabel(\"Epoch\")\n","        plt.ylabel(\"Average Loss\")\n","        plt.title(\"Loss Evolution over Epochs\")\n","        plt.grid(True)\n","        plt.legend()\n","        plt.show()\n","\n","    if show_batch_loss:\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(range(1, len(batch_losses) + 1), batch_losses, marker='x', label='Batch Loss', color='orange')\n","        plt.xlabel(\"Batch\")\n","        plt.ylabel(\"Loss\")\n","        plt.title(\"Loss Evolution over Batches\")\n","        plt.grid(True)\n","        plt.legend()\n","        plt.show()\n","\n","# Plot the performance\n","plot_performance()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP53tMQgfQmKQgonnKr5kNa","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}